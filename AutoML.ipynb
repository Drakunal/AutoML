{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e60e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to store and save the model details along with evaluation metrics\n",
    "class ModelObject:\n",
    "    def __init__(self, model_name, model, params, best_params, evaluation_metrics, version):\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.best_params = best_params\n",
    "        self.evaluation_metrics = evaluation_metrics\n",
    "        self.version = version\n",
    "    def log_details(self):\n",
    "        log_message = f\"Model: {self.model_name} (Version: {self.version})\\n\"\n",
    "        log_message += f\"Initial Parameters: {self.params}\\n\"\n",
    "        log_message += f\"Best Parameters after tuning: {self.best_params}\\n\"\n",
    "        log_message += f\"Evaluation Metrics: {self.evaluation_metrics}\\n\"\n",
    "        return log_message\n",
    "\n",
    "    def save(self, save_path):\n",
    "        joblib.dump(self, save_path)\n",
    "        print(f\"Model saved at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973d5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Class for Dataset Handling\n",
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.target = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load Iris dataset\n",
    "        iris = load_iris()\n",
    "        self.data = iris.data\n",
    "        self.target = iris.target\n",
    "\n",
    "    def preprocess(self):\n",
    "        # Train-test split\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.data, self.target, test_size=0.2, random_state=42\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76ef3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Class for Model Selection and Tuning\n",
    "class ModelSelector:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'RandomForest': RandomForestClassifier(),\n",
    "            'SVM': SVC(),\n",
    "            'LogisticRegression': LogisticRegression(max_iter=200)\n",
    "        }\n",
    "        self.best_model_object = None\n",
    "        self.version = 1  # Versioning starts at 1\n",
    "\n",
    "    def hyperparameter_tuning(self, model, param_grid, X_train, y_train):\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        return grid_search.best_estimator_, grid_search.best_params_\n",
    "\n",
    "    def select_model(self, X_train, y_train, X_test, y_test):\n",
    "        # Define parameter grids for each model\n",
    "        param_grids = {\n",
    "            'RandomForest': {'n_estimators': [10, 50, 100], 'max_depth': [3, 5, 7]},\n",
    "            'SVM': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "            'LogisticRegression': {'C': [0.01, 0.1, 1]}\n",
    "        }\n",
    "\n",
    "        best_score = 0\n",
    "        for model_name, model in self.models.items():\n",
    "            print(f\"Tuning {model_name}...\")\n",
    "            tuned_model, best_params = self.hyperparameter_tuning(model, param_grids[model_name], X_train, y_train)\n",
    "            \n",
    "            # Evaluate on test data\n",
    "            y_pred = tuned_model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            evaluation_metrics = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "            print(f\"{model_name} Test Accuracy: {accuracy}\")\n",
    "\n",
    "            # Save model object only if it is the best one\n",
    "            if accuracy > best_score:\n",
    "                best_score = accuracy\n",
    "                self.best_model_object = ModelObject(\n",
    "                    model_name=model_name,\n",
    "                    model=tuned_model,\n",
    "                    params=param_grids[model_name],\n",
    "                    best_params=best_params,\n",
    "                    evaluation_metrics={\"accuracy\": accuracy, \"classification_report\": evaluation_metrics},\n",
    "                    version=self.version\n",
    "                )\n",
    "\n",
    "        print(f\"Best Model: {self.best_model_object.model_name}\")\n",
    "        return self.best_model_object\n",
    "\n",
    "    def save_best_model(self):\n",
    "        if self.best_model_object:\n",
    "            # Create the model's versioned file name\n",
    "            save_path = f\"{self.best_model_object.model_name}_v{self.version}.pkl\"\n",
    "            self.best_model_object.save(save_path)\n",
    "            self.version += 1  # Increment the version for the next save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e7b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main AutoML Pipeline\n",
    "class AutoMLPipeline:\n",
    "    def __init__(self):\n",
    "        self.dataset = Dataset()\n",
    "        self.model_selector = ModelSelector()\n",
    "\n",
    "    def run(self):\n",
    "        # Load and preprocess data\n",
    "        print(\"Loading and Preprocessing Data...\")\n",
    "        self.dataset.load_data()\n",
    "        self.dataset.preprocess()\n",
    "\n",
    "        # Model Selection and Evaluation\n",
    "        print(\"Selecting the best model...\")\n",
    "        best_model = self.model_selector.select_model(\n",
    "            self.dataset.X_train, self.dataset.y_train, \n",
    "            self.dataset.X_test, self.dataset.y_test\n",
    "        )\n",
    "\n",
    "        # Save the best model with versioning\n",
    "        self.model_selector.save_best_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the AutoML pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    pipeline = AutoMLPipeline()\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Path to the saved model file (replace with your file path)\n",
    "model_file_path = 'RandomForest_v1.pkl'\n",
    "\n",
    "# Load the ModelObject instance\n",
    "loaded_model_object = joblib.load(model_file_path)\n",
    "\n",
    "# Inspect the contents of the loaded model object\n",
    "print(f\"Model Name: {loaded_model_object.model_name}\")\n",
    "print(f\"Version: {loaded_model_object.version}\")\n",
    "print(f\"Parameters: {loaded_model_object.params}\")\n",
    "print(f\"Best Parameters: {loaded_model_object.best_params}\")\n",
    "print(f\"Evaluation Metrics: {loaded_model_object.evaluation_metrics}\")\n",
    "\n",
    "# To inspect the model itself, use the sklearn model's methods\n",
    "model = loaded_model_object.model\n",
    "print(f\"Model: {model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b59c61",
   "metadata": {},
   "source": [
    "#### **Pipeline Overview**\n",
    "This AutoML pipeline automates the process of training, tuning, evaluating, and saving machine learning models with key information. The pipeline performs the following tasks:\n",
    "1. **Data Preprocessing**: Loading the Iris dataset and splitting it into training and testing sets.\n",
    "2. **Model Selection**: Training multiple machine learning models (RandomForest, SVM, and LogisticRegression), performing hyperparameter tuning, and selecting the best-performing model.\n",
    "3. **Model Saving**: The best model is saved as a versioned object along with its name, parameters, best hyperparameters, evaluation metrics (accuracy and classification report), and version number.\n",
    "4. **Version Control**: Each best model is saved with a version number, allowing users to keep track of different versions of the models.\n",
    "\n",
    "#### **Key Components**\n",
    "\n",
    "1. **`ModelObject` Class**:\n",
    "   - Stores the details of the trained model, including the model name, initial and best parameters, evaluation metrics, and version number.\n",
    "   - It has a `log_details()` method to log important information about the model, and a `save()` method to save the object using `joblib`.\n",
    "\n",
    "2. **`Dataset` Class**:\n",
    "   - Handles loading and splitting the data.\n",
    "   - In this case, it loads the Iris dataset and splits it into training and test sets.\n",
    "\n",
    "3. **`ModelSelector` Class**:\n",
    "   - Defines the available models (`RandomForest`, `SVM`, and `LogisticRegression`).\n",
    "   - Uses `GridSearchCV` to perform hyperparameter tuning on each model and selects the model with the highest test accuracy.\n",
    "   - Saves the best model using the `ModelObject` class, while keeping track of the versioning.\n",
    "\n",
    "4. **`AutoMLPipeline` Class**:\n",
    "   - Orchestrates the entire process.\n",
    "   - Runs data preprocessing, model selection, and model saving.\n",
    "\n",
    "5. **Version Control**:\n",
    "   - The pipeline saves the best model with a version number, starting from 1 and incrementing with each save.\n",
    "\n",
    "#### **How It Works**:\n",
    "1. The pipeline loads the Iris dataset, splits it into training and test sets, and preprocesses the data.\n",
    "2. Three models (`RandomForest`, `SVM`, and `LogisticRegression`) are trained using a grid search for hyperparameter tuning.\n",
    "3. The model with the best accuracy is selected and its details (name, parameters, evaluation metrics) are saved in a versioned object using `joblib`.\n",
    "4. Each saved model is tagged with a version number for easy version control and tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade4929",
   "metadata": {},
   "source": [
    "# AutoML\n",
    "In a typical **AutoML** workflow, the steps like **data visualization, feature engineering, attribute selection, and exploratory data analysis (EDA)** are often considered part of the **data scientist's or data analyst's** role, rather than being part of the AutoML system itself. \n",
    "\n",
    "\n",
    "### 1. **Data Visualization**:\n",
    "   - **Purpose**: Data visualization is typically used to understand the distribution of features, detect outliers, and identify patterns before modeling. \n",
    "   - **Role**: It helps data scientists or analysts understand the data better and decide on potential feature transformations or selections.\n",
    "   - **Why not in AutoML**: Visualization is often manual and interpretative. It’s done as a pre-processing step before applying an AutoML system.\n",
    "\n",
    "### 2. **Feature Engineering**:\n",
    "   - **Purpose**: Transforming or creating new features from raw data, such as normalizing, encoding categorical variables, or creating interaction terms.\n",
    "   - **Role**: This is where data analysts and scientists come in to apply domain knowledge to craft features that will improve model performance.\n",
    "   - **Why not in AutoML**: AutoML systems might automate some basic feature engineering tasks (e.g., scaling, one-hot encoding), but domain-specific feature engineering is usually performed outside the AutoML process by data scientists.\n",
    "\n",
    "### 3. **Attribute/Feature Selection**:\n",
    "   - **Purpose**: Selecting the most relevant features to improve model accuracy and avoid overfitting.\n",
    "   - **Role**: Some AutoML frameworks offer automatic feature selection, but typically, data scientists analyze feature importance to make more intelligent selections.\n",
    "   - **Why not in AutoML**: While automated feature selection can happen as part of AutoML, more advanced or domain-specific decisions are generally made by data scientists manually.\n",
    "\n",
    "### 4. **Exploratory Data Analysis (EDA)**:\n",
    "   - **Purpose**: Understanding the data distributions, relationships, and anomalies through statistical and graphical analysis.\n",
    "   - **Role**: EDA is crucial for gaining insights into the dataset before building models. It helps in decision-making for data cleaning, feature engineering, and model selection.\n",
    "   - **Why not in AutoML**: EDA is largely interpretive and manual. AutoML focuses on training, tuning, and evaluating models based on the processed data, but doesn't perform in-depth statistical or graphical analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**:\n",
    "- **Data Analysts or Data Scientists** typically handle **EDA, feature engineering, attribute selection, and visualization** before feeding the data into an AutoML system. \n",
    "- **ML Engineers or AutoML Systems** take preprocessed data and focus on **model selection, hyperparameter tuning, training, evaluation, and model deployment**.\n",
    "\n",
    "AutoML helps by automating the **model-building process** (which includes tasks like hyperparameter tuning, cross-validation, and model evaluation), but it generally expects **cleaned and pre-processed data** as input, which is where the data scientist’s role comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f3460",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **README File**\n",
    "\n",
    "Here's a `README.md` file for your project:\n",
    "\n",
    "```markdown\n",
    "# AutoML Pipeline for Model Selection and Versioning\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project implements an automated machine learning (AutoML) pipeline to select the best model, tune its hyperparameters, and save it with detailed information, including model name, parameters, evaluation metrics, and version number. The pipeline uses Python and scikit-learn and is designed for simplicity and extendability.\n",
    "\n",
    "The pipeline currently supports:\n",
    "- Random Forest\n",
    "- Support Vector Machine (SVM)\n",
    "- Logistic Regression\n",
    "\n",
    "The best model is saved as a versioned object, making it easy to track changes over time.\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "```\n",
    ".\n",
    "├── automl_pipeline.py   # Main code file for the AutoML pipeline\n",
    "├── README.md            # Project description and usage\n",
    "└── models               # Folder where versioned model files will be saved\n",
    "```\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. **Dataset**: The pipeline uses the Iris dataset (loaded from `sklearn`).\n",
    "2. **Model Selection**: The pipeline trains three models (`RandomForest`, `SVM`, and `LogisticRegression`), tunes their hyperparameters using grid search, and selects the best model based on test accuracy.\n",
    "3. **Model Saving**: The best model is saved as an object, which contains:\n",
    "   - Model Name\n",
    "   - Initial and Best Hyperparameters\n",
    "   - Evaluation Metrics (Accuracy and Classification Report)\n",
    "   - Version Number\n",
    "4. **Version Control**: Each saved model is assigned a version number, allowing you to keep track of different model versions easily.\n",
    "\n",
    "## Installation\n",
    "\n",
    "1. Clone this repository:\n",
    "   ```bash\n",
    "   git clone <repository-url>\n",
    "   cd <repository-folder>\n",
    "   ```\n",
    "\n",
    "2. Install dependencies:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "   The key dependencies are:\n",
    "   - `scikit-learn`\n",
    "   - `joblib`\n",
    "\n",
    "## Running the Pipeline\n",
    "\n",
    "Run the pipeline using the following command:\n",
    "\n",
    "```bash\n",
    "python automl_pipeline.py\n",
    "```\n",
    "\n",
    "The pipeline will:\n",
    "- Load and preprocess the Iris dataset.\n",
    "- Train, tune, and evaluate three different models.\n",
    "- Select the best-performing model and save it as a versioned object in the `models/` directory.\n",
    "\n",
    "## Saved Models\n",
    "\n",
    "Each best model will be saved in the `models/` directory with a filename format like:\n",
    "```\n",
    "RandomForest_v1.pkl\n",
    "SVM_v2.pkl\n",
    "```\n",
    "\n",
    "These files contain all the information about the model, including:\n",
    "- Model Name\n",
    "- Parameters and Best Parameters\n",
    "- Evaluation Metrics\n",
    "- Version Number\n",
    "\n",
    "## Loading and Inspecting Saved Models\n",
    "\n",
    "To load a saved model and inspect its contents, use the following code:\n",
    "\n",
    "```python\n",
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "model_file = 'models/RandomForest_v1.pkl'  # Replace with the actual file path\n",
    "loaded_model = joblib.load(model_file)\n",
    "\n",
    "# Access the model details\n",
    "print(f\"Model Name: {loaded_model.model_name}\")\n",
    "print(f\"Version: {loaded_model.version}\")\n",
    "print(f\"Parameters: {loaded_model.params}\")\n",
    "print(f\"Best Parameters: {loaded_model.best_params}\")\n",
    "print(f\"Evaluation Metrics: {loaded_model.evaluation_metrics}\")\n",
    "\n",
    "# Access the actual trained model\n",
    "trained_model = loaded_model.model\n",
    "print(trained_model)\n",
    "```\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Automated Model Selection**: Automatically trains and tunes multiple models to select the best one.\n",
    "- **Versioned Model Saving**: Each model is saved with a version number for easy tracking.\n",
    "- **Hyperparameter Tuning**: Uses grid search for hyperparameter tuning to find the best configuration for each model.\n",
    "- **Model Evaluation**: Reports accuracy and detailed classification metrics for the best model.\n",
    "\n",
    "## Future Work\n",
    "\n",
    "- Add support for additional machine learning algorithms.\n",
    "- Automate feature selection and lightweight feature engineering.\n",
    "- Integrate with other datasets for a more general pipeline.\n",
    "\n",
    "## License\n",
    "\n",
    "This project is licensed under the MIT License. Feel free to use and modify the code.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation of the `README.md`**:\n",
    "1. **Overview**: Explains the purpose and functionality of the AutoML pipeline.\n",
    "2. **Installation**: Instructions to install the necessary libraries (`scikit-learn` and `joblib`).\n",
    "3. **Running the Pipeline**: How to run the pipeline and what happens when you do.\n",
    "4. **Saved Models**: Describes how models are saved with version control and how to load them.\n",
    "5. **Key Features**: Summarizes what the pipeline offers in terms of automated model selection and version control.\n",
    "6. **Future Work**: Suggests possible future extensions for the project.\n",
    "\n",
    "This file will serve as a helpful guide for anyone using your code, detailing how to run the pipeline, save models, and reload them for inspection.\n",
    "\n",
    "Let me know if you'd like any adjustments or additional information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8004380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
